# -*- coding: utf-8 -*-
"""Region Growing Algorithm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GRQObnTONczbX6OorYE9pYqP9h_NG4X7
"""

import cv2
import numpy as np
import os
import json
from google.colab import files
from collections import deque
from google.colab.patches import cv2_imshow # Import cv2_imshow

# =========================================================
# Upload Video
# =========================================================
uploaded = files.upload()
video_path = list(uploaded.keys())[0]
print("ðŸŽ¥ Using video:", video_path)

# =========================================================
# Region Growing Function
# =========================================================
def region_grow_lab(lab_img, seeds, thresh=5, connectivity=8):
    h, w = lab_img.shape[:2]
    visited = np.zeros((h,w), np.uint8)
    mask = np.zeros((h,w), np.uint8)

    if connectivity == 4:
        neigh = [(-1,0),(1,0),(0,-1),(0,1)]
    else:
        neigh = [(-1,0),(1,0),(0,-1),(0,1),(-1,-1),(-1,1),(1,-1),(1,1)]

    q = deque()
    for (sx, sy) in seeds:
        if 0 <= sx < w and 0 <= sy < h:
            visited[sy, sx] = 1
            mask[sy, sx] = 255
            q.append((sx, sy, lab_img[sy, sx].astype(np.float32)))

    while q:
        x, y, ref = q.popleft()
        for dx, dy in neigh:
            nx, ny = x + dx, y + dy
            if not (0 <= nx < w and 0 <= ny < h):
                continue
            if visited[ny, nx]:
                continue

            cur = lab_img[ny, nx].astype(np.float32)
            dist = np.linalg.norm(cur - ref)
            visited[ny, nx] = 1

            if dist <= thresh:
                mask[ny, nx] = 255
                q.append((nx, ny, cur))

    return mask

# =========================================================
# Annotation Function (Region Growing + MOG2)
# =========================================================
def annotate_region_growing_MOG2(
    video_path,
    out_dir="rg_annotations_mog2",
    thresh=5,
    min_area=1500
):
    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    cap = cv2.VideoCapture(video_path)
    fgbg = cv2.createBackgroundSubtractorMOG2(
        history=200,
        varThreshold=25,
        detectShadows=True
    )

    anno = []
    frame_id = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        fgmask = fgbg.apply(frame)

        # clean up noise
        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))
        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, k)

        # detect moving regions
        cnts, _ = cv2.findContours(
            fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        seeds = []
        for c in cnts:
            if cv2.contourArea(c) < min_area:
                continue
            x,y,w,h = cv2.boundingRect(c)
            cx = x + w//2
            cy = y + h//2
            seeds.append((cx, cy))

        if len(seeds) == 0:
            print(f"Frame {frame_id}: no motion detected")
            frame_id += 1
            continue

        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        rg_mask = region_grow_lab(lab, seeds, thresh)

        # bounding box from RG mask
        ys, xs = np.where(rg_mask == 255)
        if len(xs) > 0:
            x1, y1 = xs.min(), ys.min()
            x2, y2 = xs.max(), ys.max()
            bbox = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]

            mask_name = f"mask_{frame_id:04d}.png"
            cv2.imwrite(os.path.join(out_dir, mask_name), rg_mask)

            anno.append({
                "frame": frame_id,
                "mask": mask_name,
                "bbox": bbox
            })

        # Visualize (optional)
        vis = frame.copy()
        vis[rg_mask == 255] = (0,0,255)
        cv2_imshow(vis) # Corrected: Removed the first argument
        if cv2.waitKey(1) == 27:
            break

        frame_id += 1

    cap.release()
    cv2.destroyAllWindows()

    # save annotation file
    with open(os.path.join(out_dir, "annotations.json"), "w") as f:
        json.dump(anno, f, indent=4)

    print("\nâœ” Done")
    print("Frames processed:", frame_id)
    print("Masks & annotations saved at:", out_dir)


# =========================================================
# Run the Annotator
# =========================================================
annotate_region_growing_MOG2(video_path)

from google.colab import files

uploaded = files.upload()
video_path = list(uploaded.keys())[0]
print("Uploaded video:", video_path)

import cv2
import numpy as np
import os
from google.colab.patches import cv2_imshow

def region_growing(frame, seed, thresh):
    h, w = frame.shape[:2]
    visited = np.zeros((h, w), dtype=np.uint8)
    mask = np.zeros((h, w), dtype=np.uint8)

    queue = [seed]
    seed_val = frame[seed[1], seed[0]]

    while queue:
        x, y = queue.pop(0)
        if visited[y, x]:
            continue
        visited[y, x] = 1

        if abs(int(frame[y, x]) - int(seed_val)) < thresh:
            mask[y, x] = 255

            if x > 0: queue.append((x - 1, y))
            if x < w - 1: queue.append((x + 1, y))
            if y > 0: queue.append((x, y - 1))
            if y < h - 1: queue.append((x, y + 1))

    return mask


def annotate_region_growing_MOG2(video_path, thresh=20):
    cap = cv2.VideoCapture(video_path)
    fgbg = cv2.createBackgroundSubtractorMOG2()

    frame_num = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_num += 1
        print(f"Processing frame {frame_num}...")

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Apply background subtraction
        fgmask = fgbg.apply(gray)

        # Select seed point from largest contour
        contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if len(contours) > 0:
            cnt = max(contours, key=cv2.contourArea)
            M = cv2.moments(cnt)

            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                seed = (cx, cy)

                rg_mask = region_growing(gray, seed, thresh)

                vis = frame.copy()
                vis[rg_mask == 255] = (0, 0, 255)  # show region in red

                print("Region Growing + MOG2")
                cv2_imshow(vis)

        if cv2.waitKey(1) & 0xFF == 27:
            break

    cap.release()
    print("Processing complete!")

annotate_region_growing_MOG2(video_path)